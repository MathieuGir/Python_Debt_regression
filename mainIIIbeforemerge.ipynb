{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I Construction de la base de données\n",
    "\n",
    "## Régression classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Robust linear Model Regression Results                    \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   No. Observations:                  137\n",
      "Model:                            RLM   Df Residuals:                      128\n",
      "Method:                          IRLS   Df Model:                            8\n",
      "Norm:                          HuberT                                         \n",
      "Scale Est.:                       mad                                         \n",
      "Cov Type:                          H1                                         \n",
      "Date:                Sat, 30 Dec 2023                                         \n",
      "Time:                        21:21:58                                         \n",
      "No. Iterations:                     4                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                   9.45e+05   1.46e+05      6.472      0.000    6.59e+05    1.23e+06\n",
      "BOP                      12.1957      0.772     15.790      0.000      10.682      13.710\n",
      "business_insolvencies   -88.2761      6.202    -14.234      0.000    -100.432     -76.121\n",
      "firms_creation            1.9731      0.488      4.039      0.000       1.016       2.930\n",
      "natality_rate         -6.325e+04   8312.243     -7.609      0.000   -7.95e+04    -4.7e+04\n",
      "unemployment_rate      6.526e+04   9370.292      6.965      0.000    4.69e+04    8.36e+04\n",
      "Valuation                65.9044      9.354      7.046      0.000      47.571      84.238\n",
      "Exch_rate              -9.52e+04   5.76e+04     -1.653      0.098   -2.08e+05    1.77e+04\n",
      "Fixed rate             1.433e+04   8331.306      1.720      0.085   -1997.918    3.07e+04\n",
      "=========================================================================================\n",
      "\n",
      "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore .\n",
      "\n",
      "Mean Squared Error: 7490965860.043532\n",
      "R^2 Score: 0.9372781239621453\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import ruptures as rpt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "data_folder = 'datas/'\n",
    "\n",
    "final_data = pd.read_csv(os.path.join(data_folder, 'final_data.csv'), parse_dates=['DATE'])\n",
    "selected_columns = ['BOP', 'business_insolvencies', 'firms_creation', 'natality_rate', 'unemployment_rate', 'Valuation', 'Exch_rate', 'Fixed rate', 'negotiable_debts']\n",
    "df = final_data[selected_columns]\n",
    "data_for_regression = final_data[selected_columns]\n",
    "\n",
    "data_for_regression = data_for_regression.dropna()\n",
    "\n",
    "X = data_for_regression.drop(columns=['negotiable_debts'])\n",
    "Y = data_for_regression['negotiable_debts']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisation du modèle de régression linéaire avec l'option robuste\n",
    "\n",
    "model = sm.RLM(Y_train, X_train, M=sm.robust.norms.HuberT()).fit()\n",
    "print(model.summary())\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Évaluation de la performance du modèle\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "\n",
    "print(f'\\nMean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "matrix = pd.concat([Y, X], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détection de grandes périodes et points de rupture\n",
    "\n",
    "Nous venons donc de réaliser une régression linéaire classique afin de trouver des corrélations, significatives ou non, entre nos régresseurs et l'objet d'étude (la dette négociable de l'Etat). Cependant, il semble essentiel de souligner que ces corrélations peuvent changer au cours du temps. L'économie n'est pas un champ d'étude atemporel, certains coefficients devant des régresseurs peuvent positifs et significatifs pendant une certaine période, par exemple après la crise de 2008, puis perdre en significativité voire changer de signe pendant une période plus calme. Nous avons donc eu l'idée de trouver des grandes périodes de l'économie entre 2009 et 2023. Ces périodes se trouvent en cherchant des \"points de rupture\", c'est à dire des instants où les coefficients devant les régresseurs tendent à changer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points de rupture détectés : [ 40  85 135 172]\n"
     ]
    }
   ],
   "source": [
    "# Détection de changement avec ruptures pour chaque coefficient\n",
    "breakpoints = []\n",
    "for i in range(X.shape[1]):\n",
    "    algo = rpt.Pelt(model=\"rbf\").fit(matrix[:, [0, i + 1]])\n",
    "    result = algo.predict(pen=10)  # Vous pouvez ajuster le paramètre de pénalité\n",
    "    breakpoints.append(result)\n",
    "\n",
    "# Convertissez les indices des points de rupture en un seul ensemble\n",
    "breakpoints = np.unique(np.concatenate(breakpoints))\n",
    "\n",
    "# Affichez les points de rupture\n",
    "print(\"Points de rupture détectés :\", breakpoints)\n",
    "\n",
    "# Réinitialiser l'index du dataframe\n",
    "final_data = final_data.reset_index(drop=True)\n",
    "\n",
    "# On écrit alors les points de rupture détectés\n",
    "breakpoints = [0, 40, 85, 135, len(final_data) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons utilisé l'algorithme Pelt de la bibliothèque \"ruptures\" afin de détecter les points de rupture. Ce modèle Pelt utilise le modèle \"rbf\" (radial basis function) pour estimer le coût d'ajustement entre segments successifs de la série temporelle des données économiques. L'algorithme fonctionne de la manière suivante : on initie une segmentation triviale, puis on propage et ajuste itérativement cette segmentation tout en écartant les branches non prometteuses. La détection de ruptures repose sur la minimisation du coût global de la segmentation. L'Nous avons utilisé ce modèle car il permet d'identifier des périodes où les coefficients de la régression linéaire présentent des changements significatifs, facilitant ainsi l'analyse des influences temporelles sur la dette de l'État.\n",
    "\n",
    "Ainsi, nous trouvons 4 périodes. La première démarre en janvier 2009 et se termine en mai 2012, la seconde démarre en mai 2012 et se termine en février 2016. La troisième commence en février 2016 et s'achève en avril 2020. La dernière commence en avril 2020 et se termine en 2023, lors de nos dernières données. \n",
    "\n",
    "Une fois ces périodes trouvées, on peut alors reproduire une régression linéaire pour chaque segment afin de visualiser, commenter et interpréter les coefficients de chaque segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segment 1 - Period: 2009-01-01 00:00:00 to 2012-05-01 00:00:00\n",
      "                    Robust linear Model Regression Results                    \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   No. Observations:                   40\n",
      "Model:                            RLM   Df Residuals:                       31\n",
      "Method:                          IRLS   Df Model:                            8\n",
      "Norm:                          HuberT                                         \n",
      "Scale Est.:                       mad                                         \n",
      "Cov Type:                          H1                                         \n",
      "Date:                Sat, 30 Dec 2023                                         \n",
      "Time:                        21:21:58                                         \n",
      "No. Iterations:                     2                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                 -9.648e+05   3.13e+05     -3.083      0.002   -1.58e+06   -3.51e+05\n",
      "BOP                      15.3877      0.818     18.820      0.000      13.785      16.990\n",
      "business_insolvencies   -14.6154      8.243     -1.773      0.076     -30.771       1.541\n",
      "firms_creation            0.5915      0.506      1.168      0.243      -0.401       1.584\n",
      "natality_rate         -4691.2254   1.25e+04     -0.375      0.708   -2.92e+04    1.98e+04\n",
      "unemployment_rate      1.273e+05   3.01e+04      4.231      0.000    6.84e+04    1.86e+05\n",
      "Valuation                26.2901     11.186      2.350      0.019       4.365      48.215\n",
      "Exch_rate              6.799e+04   4.46e+04      1.524      0.128   -1.95e+04    1.55e+05\n",
      "Fixed rate             2.904e+04   2.39e+04      1.216      0.224   -1.78e+04    7.59e+04\n",
      "=========================================================================================\n",
      "\n",
      "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore .\n",
      "\n",
      "Segment 2 - Period: 2012-05-01 00:00:00 to 2016-02-01 00:00:00\n",
      "                    Robust linear Model Regression Results                    \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   No. Observations:                   45\n",
      "Model:                            RLM   Df Residuals:                       36\n",
      "Method:                          IRLS   Df Model:                            8\n",
      "Norm:                          HuberT                                         \n",
      "Scale Est.:                       mad                                         \n",
      "Cov Type:                          H1                                         \n",
      "Date:                Sat, 30 Dec 2023                                         \n",
      "Time:                        21:21:58                                         \n",
      "No. Iterations:                     3                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                  1.593e+06    3.5e+05      4.555      0.000    9.07e+05    2.28e+06\n",
      "BOP                       4.2799      3.092      1.384      0.166      -1.780      10.340\n",
      "business_insolvencies    -8.5819      7.658     -1.121      0.262     -23.590       6.427\n",
      "firms_creation           -0.3921      0.662     -0.592      0.554      -1.690       0.906\n",
      "natality_rate         -5656.2630   9634.032     -0.587      0.557   -2.45e+04    1.32e+04\n",
      "unemployment_rate     -1.657e+04   2.06e+04     -0.803      0.422    -5.7e+04    2.39e+04\n",
      "Valuation                16.9830     16.359      1.038      0.299     -15.081      49.047\n",
      "Exch_rate             -1.054e+05   6.27e+04     -1.680      0.093   -2.28e+05    1.75e+04\n",
      "Fixed rate            -1.734e+05   3.01e+04     -5.763      0.000   -2.32e+05   -1.14e+05\n",
      "=========================================================================================\n",
      "\n",
      "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore .\n",
      "\n",
      "Segment 3 - Period: 2016-02-01 00:00:00 to 2020-04-01 00:00:00\n",
      "                    Robust linear Model Regression Results                    \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   No. Observations:                   50\n",
      "Model:                            RLM   Df Residuals:                       42\n",
      "Method:                          IRLS   Df Model:                            7\n",
      "Norm:                          HuberT                                         \n",
      "Scale Est.:                       mad                                         \n",
      "Cov Type:                          H1                                         \n",
      "Date:                Sat, 30 Dec 2023                                         \n",
      "Time:                        21:21:58                                         \n",
      "No. Iterations:                     4                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                  2.459e+06   9.96e+04     24.702      0.000    2.26e+06    2.65e+06\n",
      "BOP                       2.7319      0.667      4.094      0.000       1.424       4.040\n",
      "business_insolvencies   -15.4886      5.510     -2.811      0.005     -26.288      -4.690\n",
      "firms_creation            0.7115      0.327      2.177      0.029       0.071       1.352\n",
      "natality_rate           339.2651   5633.504      0.060      0.952   -1.07e+04    1.14e+04\n",
      "unemployment_rate     -9.418e+04   7107.118    -13.252      0.000   -1.08e+05   -8.03e+04\n",
      "Valuation               -15.7029      7.313     -2.147      0.032     -30.037      -1.369\n",
      "Exch_rate             -2.119e+04    4.8e+04     -0.442      0.659   -1.15e+05    7.29e+04\n",
      "Fixed rate                     0          0        nan        nan           0           0\n",
      "=========================================================================================\n",
      "\n",
      "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore .\n",
      "\n",
      "Segment 4 - Period: 2020-04-01 00:00:00 to 2023-04-01 00:00:00\n",
      "                    Robust linear Model Regression Results                    \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   No. Observations:                   36\n",
      "Model:                            RLM   Df Residuals:                       27\n",
      "Method:                          IRLS   Df Model:                            8\n",
      "Norm:                          HuberT                                         \n",
      "Scale Est.:                       mad                                         \n",
      "Cov Type:                          H1                                         \n",
      "Date:                Sat, 30 Dec 2023                                         \n",
      "Time:                        21:21:58                                         \n",
      "No. Iterations:                     4                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                  1.346e+06   1.12e+05     12.038      0.000    1.13e+06    1.57e+06\n",
      "BOP                       6.1300      0.505     12.134      0.000       5.140       7.120\n",
      "business_insolvencies    -0.7117      6.838     -0.104      0.917     -14.115      12.691\n",
      "firms_creation           -0.3599      0.233     -1.545      0.122      -0.816       0.097\n",
      "natality_rate          1.761e+04   5380.000      3.273      0.001    7063.612    2.82e+04\n",
      "unemployment_rate      1.495e+04    1.2e+04      1.249      0.212   -8502.365    3.84e+04\n",
      "Valuation                 5.1150      7.622      0.671      0.502      -9.824      20.054\n",
      "Exch_rate             -7.943e+04   9.09e+04     -0.873      0.382   -2.58e+05    9.88e+04\n",
      "Fixed rate             3.663e+04   4787.129      7.652      0.000    2.73e+04     4.6e+04\n",
      "=========================================================================================\n",
      "\n",
      "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore .\n"
     ]
    }
   ],
   "source": [
    "# Extraire les dates correspondantes aux points de rupture\n",
    "breakpoint_dates = final_data.loc[breakpoints, 'DATE']\n",
    "\n",
    "# Ajustez les dates pour le premier et le dernier segment\n",
    "breakpoint_dates.iloc[0] = pd.to_datetime('2009-01-01')\n",
    "breakpoint_dates.iloc[-1] = pd.to_datetime('2023-04-01')\n",
    "\n",
    "# Diviser le dataframe en segments basés sur les dates de rupture\n",
    "segments = []\n",
    "for i in range(len(breakpoints) - 1):\n",
    "    start_date = pd.to_datetime(breakpoint_dates.iloc[i])\n",
    "    end_date = pd.to_datetime(breakpoint_dates.iloc[i + 1])\n",
    "    segment_data = final_data[(final_data['DATE'] >= start_date) & (final_data['DATE'] < end_date)]\n",
    "    segments.append(segment_data)\n",
    "\n",
    "# Ajuster une régression linéaire robuste (Huber) pour chaque segment avec statsmodels\n",
    "for i, segment_data in enumerate(segments):\n",
    "    start_date = pd.to_datetime(breakpoint_dates.iloc[i])\n",
    "    end_date = pd.to_datetime(breakpoint_dates.iloc[i + 1])\n",
    "\n",
    "    X = segment_data.drop(columns=['negotiable_debts', 'DATE', 'Deposit facility', 'Marginal lending facility'])\n",
    "    Y = segment_data['negotiable_debts']\n",
    "\n",
    "    # Ajoutez une constante à X pour estimer l'ordonnée à l'origine\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Créer un modèle de régression linéaire robuste (Huber) avec statsmodels    \n",
    "    model = sm.RLM(Y, X, M=sm.robust.norms.HuberT()).fit()\n",
    "\n",
    "    # Afficher les résultats sous forme de tableau\n",
    "    print(f\"\\nSegment {i + 1} - Period: {start_date} to {end_date}\")\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première période (2009-avril 2012) est une période post-crise 2008. Comme attendu et commenté plus haut, le coefficient devant la colonne \"Balance of payments\", \"unemployment_rate\", \"Valuation\" sont significatifs et positif. Les coefficients devant \"firms_creation\", \"natality_rate\", \"Exch_rate\" et \"Fixed rate\" sont non significatifs sûrement dû au faible nombre de données sur cette période de 3 ans. Le coefficients devant 'business_insolvencies\" est négatif mais assez faible, tout comme dans la régression globale, ce qui s'interprète donc de la même manière. Comme changement notable, la période 2009-2012 montre une amplification de l'effet de la balance des paiements sur la dette, et une relative stabilité des insolvabilités par rapport à la période complète\n",
    "\n",
    "La seconde période, entre 2012 et 2016, est marquée par une stagnation économique, un chômage grimpant et une crise dans les échanges européens. \n",
    "Comparé au segment précédent, plusieurs changements dans les coefficients sont notables :\n",
    "Le coefficient devant \"BOP\" diminue à 4.28, montrant une moindre dépendance aux échanges internationaux. Cela peut refléter une période de stabilisation après une croissance rapide des échanges dans le segment précédent.\n",
    "Peu de coefficients sont en fait toujours significatif au seuil de 10%.\n",
    "\n",
    "La troisième période, entre 2016 et 2020, est toujours une période dde stagnation économique. Le coeffiicient devant le taux de chômage devient significatif au niveau 1% et est trés bas. Le coefficient devant \"Valuation\" est significatif, comme à la première période, mais cette fois de signe opposé, il est désormais négatif. Un coefficient négatif devant \"Valuation\" suggère qu'une dépréciation de l'euro par rapport au dollar est associée à une diminution de la dette publique en France. Cela peut résulter de l'impact positif sur les exportations, réduisant la nécessité d'emprunter. De plus, si une part significative de la dette est libellée en devises étrangères, une dépréciation augmente sa valeur en euros. Cependant, l'interprétation dépend de divers facteurs économiques.\n",
    "\n",
    "La dernière période, après avril 2020 est la période durant laquelle le COVID a fragilisé l'économie française. Les seuls régresseurs ayant des coefficients significatifs sont \"BOP\", \"Fixed rate\" et \"Natality_rate\". Ceci ne semble pas absurde dans une situation où les échanges commerciaux ont connu de fortes fluctuations (à la baisse puis à la hausse), et à un moment où la BCE a relevé ses taux afin de limiter l'inflation. Pourtant non significatif aux périodes précédentes, le coefficient devant \"Natality_rate\", fortement négatif, devient significatif au seuil de 1%. C'est donc uniquement sur cette période que ce coefficient est significatif, sachant qu'il l'est sur la régression faite sur l'ensemble des données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essai et comparaison de nouveaux modèles prédictifs\n",
    "\n",
    "La dernière partie de ce projet sur la dette négociable de l'Etat français vise à étudier d'autres formes de régressions, la régression linéaire n'étant pas unique. Après plusieurs recherches sur leur existence et sur leur implantation informatique, nous avons trouvé les Arbres de décisions, les Forêts aléatoires et les modèles Adaboost. \n",
    "On commencer par évaluer  quatre modèles (Régression Linéaire, Arbre de Décision, Forêt Aléatoire et AdaBoost) en utilisant la validation croisée pour calculer les scores RMSE (Root Mean Squared Error) pour chaque pli et affiche la moyenne RMSE pour chaque modèle.\n",
    "\n",
    "Le principe ici est le suivant : La validation croisée divise l'ensemble de données en plusieurs plis et évalue le modèle sur chacun d'entre eux.\n",
    "On entraine alors le modèle plusieurs fois selon le nombre de division, chaque fois en utilisant un pli différent comme ensemble de test et les autres comme ensembles d'entraînements. Puis pour chaque pli on évalue la performance en calculant le RMSE, et on fait enfin la moyenne des RMSE. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle: Régression Linéaire\n",
      "RMSE scores: 0    59336.03\n",
      "1    66908.69\n",
      "2    68466.28\n",
      "3    63349.78\n",
      "4    52888.35\n",
      "Name: RMSE, dtype: float64\n",
      "Moyenne RMSE: 62189.826\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle: Arbre de Décision\n",
      "RMSE scores: 0     40751.59\n",
      "1    211971.48\n",
      "2     82041.12\n",
      "3    108085.41\n",
      "4     31846.40\n",
      "Name: RMSE, dtype: float64\n",
      "Moyenne RMSE: 94939.2\n",
      "\n",
      "Modèle: Forêt Aléatoire\n",
      "RMSE scores: 0     23597.67\n",
      "1    143179.64\n",
      "2     69740.45\n",
      "3     33073.32\n",
      "4     70090.54\n",
      "Name: RMSE, dtype: float64\n",
      "Moyenne RMSE: 67936.324\n",
      "\n",
      "Modèle: AdaBoost\n",
      "RMSE scores: 0    25348.86\n",
      "1    30737.27\n",
      "2    56681.79\n",
      "3    31361.72\n",
      "4    29860.40\n",
      "Name: RMSE, dtype: float64\n",
      "Moyenne RMSE: 34798.008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = final_data[selected_columns]\n",
    "df = df.dropna()\n",
    "X = df.drop('negotiable_debts', axis=1)\n",
    "y = df['negotiable_debts']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Les Modèles qu'on a choisit\n",
    "models = {\n",
    "    'Régression Linéaire': LinearRegression(),\n",
    "    'Arbre de Décision': DecisionTreeRegressor(),\n",
    "    'Forêt Aléatoire': RandomForestRegressor(),\n",
    "    'AdaBoost': AdaBoostRegressor()\n",
    "}\n",
    "\n",
    "# Évaluation des modèles avec la validation croisée\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = pd.Series(-scores, name=\"RMSE\").apply(lambda x: round(x ** 0.5, 2))\n",
    "    print(f\"Modèle: {model_name}\")\n",
    "    print(\"RMSE scores:\", rmse_scores)\n",
    "    print(f\"Moyenne RMSE: {rmse_scores.mean()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation des Résultats :\n",
    "\n",
    "### Régression Linéaire :\n",
    "Les RMSE varient significativement d'un pli à l'autre.\n",
    "La moyenne RMSE est relativement élevée (62189.83), indiquant une dispersion importante des erreurs de prédiction.\n",
    "\n",
    "###Arbre de Décision :\n",
    "Les RMSE sont très variables, avec un écart élevé entre le meilleur et le pire pli.\n",
    "La moyenne RMSE est élevée (80897.62), suggérant une performance mitigée du modèle.\n",
    "\n",
    "### Forêt Aléatoire :\n",
    "Les RMSE montrent une variabilité, mais moins prononcée que pour l'Arbre de Décision.\n",
    "La moyenne RMSE (68686.13) est relativement élevée, indiquant que le modèle ne parvient pas à prédire de manière précise.\n",
    "\n",
    "### AdaBoost :\n",
    "Les RMSE sont plus homogènes entre les plis par rapport à d'autres modèles.\n",
    "La moyenne RMSE (35294.03) est relativement basse, suggérant une meilleure performance en termes de précision de prédiction.\n",
    "\n",
    "Le modèle avec la moyenne RMSE la plus faible est donc le modèle Adaboost. \n",
    "\n",
    "## Deuxième phase : prédiction et comparaison des modèles\n",
    "L'approche ici est différente. L'objectif ici est d'appliquer les 4 modèles de régression afin de prédire la variable cible (la dette) à un instant T, par les données des régresseurs aux instants [2009-01-01 - T]. Puis, dans un second temps, comparer les prédictions des modèles entre eux, à chaque date, et les comparer à la vraie valeur de la dette à cette date donnée. \n",
    "Ensuite, le code utilise une boucle pour itérer sur les dates, entraîne les modèles sur l'ensemble d'entraînement à chaque itération, fait des prédictions sur l'ensemble de test, et stocke ces prédictions dans le DataFrame final_data. Enfin, il affiche la somme des MSE (Mean Squared Error) pour chaque modèle.\n",
    "\n",
    "Le principe est alors le suivant : La boucle itère sur chaque date à partir de la deuxième date dans le jeu de données.À chaque itération, les données jusqu'à la date actuelle sont utilisées pour l'entraînement, tandis que les données à la date actuelle sont utilisées pour les tests.\n",
    "On entraine ensuite le modèle : Pour chaque date, les modèles sélectionnés (Régression Linéaire, Arbre de Décision, Forêt Aléatoire, AdaBoost) sont entraînés sur les caractéristiques sélectionnées jusqu'à la date actuelle.Puis on fait des prédictions à la datte actuelle, la prédiction est stockée et ajoutée à la base de données pour chaque modèles. Enfin on calcule la MSE (mean squared error) pour chaque modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:46<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somme des MSE pour Régression Linéaire: 519500253.57943726\n",
      "Somme des MSE pour Arbre de Décision: 87644044510.0\n",
      "Somme des MSE pour Forêt Aléatoire: 202128015272.33408\n",
      "Somme des MSE pour AdaBoost: 240566010187.07565\n",
      "5 dernières lignes de final_data :\n",
      "          DATE  negotiable_debts       BOP  business_insolvencies  \\\n",
      "167 2022-12-01           2277811  104521.0            4003.000000   \n",
      "168 2023-01-01           2297631  109080.0            4872.000000   \n",
      "169 2023-02-01           2319193  109849.0            4872.000000   \n",
      "170 2023-03-01           2328956  109785.0            4872.000000   \n",
      "171 2023-04-01           2352050  109339.0            4488.666667   \n",
      "\n",
      "     firms_creation  natality_rate  unemployment_rate  Valuation  Exch_rate  \\\n",
      "167         89608.0           10.0           6.933333    6473.76     1.0702   \n",
      "168         89832.0            9.6           6.900000    7082.42     1.0862   \n",
      "169         85940.0            9.8           6.933333    7267.93     1.0576   \n",
      "170         99475.0            9.4           6.966667    7322.39     1.0839   \n",
      "171         85602.0            9.3           7.000000    7491.50     1.1020   \n",
      "\n",
      "     Deposit facility  Fixed rate  Marginal lending facility  \\\n",
      "167               2.0         2.5                       2.75   \n",
      "168               2.0         2.5                       2.75   \n",
      "169               2.5         3.0                       3.25   \n",
      "170               3.0         3.5                       3.75   \n",
      "171               3.0         3.5                       3.75   \n",
      "\n",
      "     Régression Linéaire_Prediction  Arbre de Décision_Prediction  \\\n",
      "167                       2277811.0                     2266628.0   \n",
      "168                       2297631.0                     2277811.0   \n",
      "169                       2319193.0                     2297631.0   \n",
      "170                       2328956.0                     2297631.0   \n",
      "171                       2352050.0                     2297631.0   \n",
      "\n",
      "     Forêt Aléatoire_Prediction  AdaBoost_Prediction  \n",
      "167                  2219720.46         2.208045e+06  \n",
      "168                  2263278.16         2.242439e+06  \n",
      "169                  2278191.28         2.259184e+06  \n",
      "170                  2299175.08         2.275486e+06  \n",
      "171                  2307061.33         2.278702e+06  \n",
      "\n",
      "5 premières lignes de final_data :\n",
      "        DATE  negotiable_debts      BOP  business_insolvencies  \\\n",
      "0 2009-01-01           1018094  55163.0                 5758.0   \n",
      "1 2009-02-01           1040865  54216.0                 5758.0   \n",
      "2 2009-03-01           1063788  52910.0                 5758.0   \n",
      "3 2009-04-01           1074757  52416.0                 5316.0   \n",
      "4 2009-05-01           1092161  54464.0                 5316.0   \n",
      "\n",
      "   firms_creation  natality_rate  unemployment_rate  Valuation  Exch_rate  \\\n",
      "0         39666.0           12.5           8.200000    2973.92     1.2782   \n",
      "1         45656.0           12.3           8.433333    2702.48     1.2669   \n",
      "2         57577.0           12.2           8.666667    2807.34     1.3251   \n",
      "3         56132.0           12.4           8.900000    3159.85     1.3226   \n",
      "4         48641.0           12.4           8.900000    3277.65     1.4154   \n",
      "\n",
      "   Deposit facility  Fixed rate  Marginal lending facility  \\\n",
      "0              1.00        2.00                       3.00   \n",
      "1              1.00        2.00                       3.00   \n",
      "2              0.50        1.50                       2.50   \n",
      "3              0.25        1.25                       2.25   \n",
      "4              0.25        1.00                       1.75   \n",
      "\n",
      "   Régression Linéaire_Prediction  Arbre de Décision_Prediction  \\\n",
      "0                             NaN                           NaN   \n",
      "1                    1.018094e+06                     1018094.0   \n",
      "2                    1.064775e+06                     1040865.0   \n",
      "3                    1.074743e+06                     1018094.0   \n",
      "4                    1.092080e+06                     1074757.0   \n",
      "\n",
      "   Forêt Aléatoire_Prediction  AdaBoost_Prediction  \n",
      "0                         NaN                  NaN  \n",
      "1                  1018094.00            1018094.0  \n",
      "2                  1033350.57            1040865.0  \n",
      "3                  1048001.53            1040865.0  \n",
      "4                  1062994.09            1063788.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Créer un dictionnaire pour stocker les métriques pour chaque modèle\n",
    "metrics_scores = {model_name: {'MSE': []} for model_name in models.keys()}\n",
    "\n",
    "# Création d'un nouveau df pour stocker les prédictions\n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df.dropna()\n",
    "\n",
    "# Variables explicatives\n",
    "features = ['BOP', 'business_insolvencies', 'firms_creation', 'natality_rate', 'unemployment_rate', 'Valuation', 'Exch_rate', 'Fixed rate', 'negotiable_debts']\n",
    "\n",
    "# Création d'un dictionnaire pour stocker les MSE pour chaque modèle\n",
    "mse_scores = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "# Désactiver les avertissements pendant l'exécution de la boucle\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Boucle sur les dates à partir de la deuxième date\n",
    "    for i in tqdm(range(1, len(final_data))):\n",
    "        # Séparer les données en ensemble d'entraînement et de test\n",
    "        train_data = final_data.iloc[:i, :]\n",
    "        test_data = final_data.iloc[i, :]\n",
    "\n",
    "        # Sélectionner les caractéristiques et la cible\n",
    "        X_train = train_data[features]\n",
    "        y_train = train_data['negotiable_debts']\n",
    "        X_test = test_data[features]\n",
    "\n",
    "        # Boucle sur les modèles\n",
    "        for model_name, model in models.items():\n",
    "            # Entraîner le modèle\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Faire la prédiction sur les données de test\n",
    "            y_pred = model.predict(X_test.values.reshape(1, -1))\n",
    "\n",
    "            # Ajouter les prédictions au DataFrame final_data\n",
    "            final_data.at[test_data.name, f'{model_name}_Prediction'] = y_pred[0]\n",
    "\n",
    "            # Calculer les métriques et les ajouter aux listes correspondantes\n",
    "            mse = mean_squared_error([test_data['negotiable_debts']], [y_pred])\n",
    "\n",
    "            metrics_scores[model_name]['MSE'].append(mse)\n",
    "\n",
    "# Afficher les métriques pour chaque modèle\n",
    "for model_name, metrics_dict in metrics_scores.items():\n",
    "    total_mse = np.sum(metrics_dict['MSE'])\n",
    "    print(f'Somme des MSE pour {model_name}: {total_mse}')\n",
    "   \n",
    "# Afficher les 5 dernières lignes\n",
    "print(\"5 dernières lignes de final_data :\")\n",
    "print(final_data.tail())\n",
    "\n",
    "# Afficher les 5 premières lignes\n",
    "print(\"\\n5 premières lignes de final_data :\")\n",
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somme des MSE pour Chaque Modèle :\n",
    "\n",
    "La somme des MSE est la plus basse pour la Régression Linéaire, indiquant une performance globale relativement meilleure par rapport aux autres modèles.\n",
    "L'Arbre de Décision a une somme des MSE très élevée, soulignant une faible capacité du modèle à généraliser.\n",
    "Forêt Aléatoire et AdaBoost ont des sommes intermédiaires, avec AdaBoost présentant une performance légèrement meilleure.\n",
    "\n",
    "### Pourquoi les résultats diffèrent selon l'approche par les RMSE et les MSE ? \n",
    "Le RMSE moyen privilégie les modèles qui minimisent les erreurs pour chaque pli, même si cela conduit à quelques erreurs importantes.\n",
    "La somme des MSE évalue les modèles en fonction de la contribution totale des erreurs, ce qui peut montrer que la Régression Linéaire a une performance plus stable sur l'ensemble des donnée. Cela peut signifier que la Régression Linéaire a moins tendance à générer des erreurs très importantes. \n",
    "\n",
    "### Conclusion \n",
    "En conclusion, même si le RMSE moyen pour AdaBoost semble meilleur, la somme des MSE indique que la Régression Linéaire peut présenter une performance plus stable et globalement meilleure sur l'ensemble des données. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I Construction de la base de données\n",
    "\n",
    "## Régression classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   R-squared:                       0.971\n",
      "Model:                            OLS   Adj. R-squared:                  0.969\n",
      "Method:                 Least Squares   F-statistic:                     535.9\n",
      "Date:                Sat, 30 Dec 2023   Prob (F-statistic):           1.69e-94\n",
      "Time:                        19:23:57   Log-Likelihood:                -1692.4\n",
      "No. Observations:                 137   AIC:                             3403.\n",
      "Df Residuals:                     128   BIC:                             3429.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                   1.63e+06   1.84e+05      8.842      0.000    1.27e+06    1.99e+06\n",
      "BOP                      10.3148      0.975     10.576      0.000       8.385      12.244\n",
      "business_insolvencies  -100.6846      7.831    -12.857      0.000    -116.180     -85.189\n",
      "firms_creation            1.3870      0.617      2.249      0.026       0.167       2.607\n",
      "natality_rate         -8.087e+04   1.05e+04     -7.705      0.000   -1.02e+05   -6.01e+04\n",
      "unemployment_rate      5.217e+04   1.18e+04      4.409      0.000    2.88e+04    7.56e+04\n",
      "Valuation               5.93e+04   1.18e+04      5.021      0.000    3.59e+04    8.27e+04\n",
      "Exch_rate             -1.725e+05   7.27e+04     -2.372      0.019   -3.16e+05   -2.86e+04\n",
      "Fixed rate             1.268e+04   1.05e+04      1.205      0.230   -8139.123    3.35e+04\n",
      "==============================================================================\n",
      "Omnibus:                       16.298   Durbin-Watson:                   1.716\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.546\n",
      "Skew:                           0.787   Prob(JB):                     9.39e-05\n",
      "Kurtosis:                       3.879   Cond. No.                     3.67e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.67e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Mean Squared Error: 5835123635.449173\n",
      "R^2 Score: 0.9511424950845961\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import ruptures as rpt\n",
    "\n",
    "data_folder = 'datas/'\n",
    "\n",
    "# Charger le DataFrame à partir du fichier CSV\n",
    "final_data = pd.read_csv(os.path.join(data_folder, 'final_data.csv'), parse_dates=['DATE'])\n",
    "\n",
    "# Ajouter les colonnes à retirer à la liste selected_columns\n",
    "selected_columns = ['BOP', 'business_insolvencies', 'firms_creation', 'natality_rate', 'unemployment_rate', 'Valuation', 'Exch_rate', 'Fixed rate', 'negotiable_debts']\n",
    "\n",
    "\n",
    "# Sélectionner les colonnes nécessaires\n",
    "data_for_regression = final_data[selected_columns]\n",
    "\n",
    "data_for_regression = data_for_regression.dropna()\n",
    "\n",
    "# Retirer les colonnes spécifiées de X\n",
    "X = data_for_regression.drop(columns=['negotiable_debts'])\n",
    "Y = data_for_regression['negotiable_debts']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser le modèle de régression linéaire avec statsmodels\n",
    "model = sm.OLS(Y_train, X_train).fit()\n",
    "\n",
    "# Imprimer un résumé des statistiques du modèle\n",
    "print(model.summary())\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Évaluer la performance du modèle\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "r2 = r2_score(Y_test, predictions)\n",
    "\n",
    "print(f'\\nMean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "matrix = pd.concat([Y, X], axis=1).to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détection de grandes périodes et points de rupture\n",
    "\n",
    "Nous venons donc de réaliser une régression linéaire classique afin de trouver des corrélations, significatives ou non, entre nos régresseurs et l'objet d'étude (la dette négociable de l'Etat). Cependant, il semble essentiel de souligner que ces corrélations peuvent changer au cours du temps. L'économie n'est pas un champ d'étude atemporel, certains coefficients devant des régresseurs peuvent positifs et significatifs pendant une certaine période, par exemple après la crise de 2008, puis perdre en significativité voire changer de signe pendant une période plus calme. Nous avons donc eu l'idée de trouver des grandes périodes de l'économie entre 2009 et 2023. Ces périodes se trouvent en cherchant des \"points de rupture\", c'est à dire des instants où les coefficients devant les régresseurs tendent à changer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points de rupture détectés : [ 40  85 135 172]\n"
     ]
    }
   ],
   "source": [
    "# Détection de changement avec ruptures pour chaque coefficient\n",
    "breakpoints = []\n",
    "for i in range(X.shape[1]):\n",
    "    algo = rpt.Pelt(model=\"rbf\").fit(matrix[:, [0, i + 1]])\n",
    "    result = algo.predict(pen=10)  # Vous pouvez ajuster le paramètre de pénalité\n",
    "    breakpoints.append(result)\n",
    "\n",
    "# Convertissez les indices des points de rupture en un seul ensemble\n",
    "breakpoints = np.unique(np.concatenate(breakpoints))\n",
    "\n",
    "# Affichez les points de rupture\n",
    "print(\"Points de rupture détectés :\", breakpoints)\n",
    "\n",
    "# Réinitialiser l'index du dataframe\n",
    "final_data = final_data.reset_index(drop=True)\n",
    "\n",
    "# On écrit alors les points de rupture détectés\n",
    "breakpoints = [0, 40, 85, 135, len(final_data) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons utilisé l'algorithme Pelt de la bibliothèque \"ruptures\" afin de détecter les points de rupture. Ce modèle Pelt utilise le modèle \"rbf\" (radial basis function) pour estimer le coût d'ajustement entre segments successifs de la série temporelle des données économiques. L'algorithme fonctionne de la manière suivante : on initie une segmentation triviale, puis on propage et ajuste itérativement cette segmentation tout en écartant les branches non prometteuses. La détection de ruptures repose sur la minimisation du coût global de la segmentation. L'Nous avons utilisé ce modèle car il permet d'identifier des périodes où les coefficients de la régression linéaire présentent des changements significatifs, facilitant ainsi l'analyse des influences temporelles sur la dette de l'État.\n",
    "\n",
    "Ainsi, nous trouvons 4 périodes. La première démarre en janvier 2009 et se termine en mai 2012, la seconde démarre en mai 2012 et se termine en février 2016. La troisième commence en février 2016 et s'achève en avril 2020. La dernière commence en avril 2020 et se termine en 2023, lors de nos dernières données. \n",
    "\n",
    "Une fois ces périodes trouvées, on peut alors reproduire une régression linéaire pour chaque segment afin de visualiser, commenter et interpréter les coefficients de chaque segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segment 1 - Period: 2009-01-01 00:00:00 to 2012-05-01 00:00:00\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   R-squared:                       0.980\n",
      "Model:                            OLS   Adj. R-squared:                  0.975\n",
      "Method:                 Least Squares   F-statistic:                     188.2\n",
      "Date:                Sat, 30 Dec 2023   Prob (F-statistic):           4.46e-24\n",
      "Time:                        19:23:57   Log-Likelihood:                -434.93\n",
      "No. Observations:                  40   AIC:                             887.9\n",
      "Df Residuals:                      31   BIC:                             903.1\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                 -9.602e+05   2.96e+05     -3.249      0.003   -1.56e+06   -3.57e+05\n",
      "BOP                      15.3978      0.772     19.940      0.000      13.823      16.973\n",
      "business_insolvencies   -14.5634      7.785     -1.871      0.071     -30.441       1.314\n",
      "firms_creation            0.5939      0.478      1.242      0.224      -0.381       1.569\n",
      "natality_rate         -4524.5680   1.18e+04     -0.383      0.704   -2.86e+04    1.96e+04\n",
      "unemployment_rate      1.266e+05   2.84e+04      4.453      0.000    6.86e+04    1.85e+05\n",
      "Valuation              2.593e+04   1.06e+04      2.454      0.020    4381.626    4.75e+04\n",
      "Exch_rate              6.878e+04   4.21e+04      1.632      0.113   -1.72e+04    1.55e+05\n",
      "Fixed rate             2.836e+04   2.26e+04      1.257      0.218   -1.77e+04    7.44e+04\n",
      "==============================================================================\n",
      "Omnibus:                        5.165   Durbin-Watson:                   2.430\n",
      "Prob(Omnibus):                  0.076   Jarque-Bera (JB):                2.010\n",
      "Skew:                           0.127   Prob(JB):                        0.366\n",
      "Kurtosis:                       1.931   Cond. No.                     1.02e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.02e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Segment 2 - Period: 2012-05-01 00:00:00 to 2016-02-01 00:00:00\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.941\n",
      "Method:                 Least Squares   F-statistic:                     88.19\n",
      "Date:                Sat, 30 Dec 2023   Prob (F-statistic):           2.59e-21\n",
      "Time:                        19:23:57   Log-Likelihood:                -499.10\n",
      "No. Observations:                  45   AIC:                             1016.\n",
      "Df Residuals:                      36   BIC:                             1032.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                  1.589e+06   3.26e+05      4.877      0.000    9.28e+05    2.25e+06\n",
      "BOP                       4.6139      2.880      1.602      0.118      -1.226      10.454\n",
      "business_insolvencies    -8.2868      7.132     -1.162      0.253     -22.752       6.178\n",
      "firms_creation           -0.4534      0.617     -0.735      0.467      -1.704       0.797\n",
      "natality_rate         -6852.6761   8973.376     -0.764      0.450   -2.51e+04    1.13e+04\n",
      "unemployment_rate     -1.633e+04   1.92e+04     -0.850      0.401   -5.53e+04    2.26e+04\n",
      "Valuation              1.421e+04   1.52e+04      0.933      0.357   -1.67e+04    4.51e+04\n",
      "Exch_rate             -9.933e+04   5.84e+04     -1.700      0.098   -2.18e+05    1.92e+04\n",
      "Fixed rate            -1.762e+05    2.8e+04     -6.287      0.000   -2.33e+05   -1.19e+05\n",
      "==============================================================================\n",
      "Omnibus:                        1.743   Durbin-Watson:                   1.191\n",
      "Prob(Omnibus):                  0.418   Jarque-Bera (JB):                1.468\n",
      "Skew:                           0.284   Prob(JB):                        0.480\n",
      "Kurtosis:                       2.321   Cond. No.                     1.05e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.05e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Segment 3 - Period: 2016-02-01 00:00:00 to 2020-04-01 00:00:00\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   R-squared:                       0.974\n",
      "Model:                            OLS   Adj. R-squared:                  0.969\n",
      "Method:                 Least Squares   F-statistic:                     221.2\n",
      "Date:                Sat, 30 Dec 2023   Prob (F-statistic):           5.03e-31\n",
      "Time:                        19:23:57   Log-Likelihood:                -543.50\n",
      "No. Observations:                  50   AIC:                             1103.\n",
      "Df Residuals:                      42   BIC:                             1118.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                  2.464e+06   1.02e+05     24.242      0.000    2.26e+06    2.67e+06\n",
      "BOP                       2.8367      0.681      4.164      0.000       1.462       4.211\n",
      "business_insolvencies   -17.5487      5.625     -3.120      0.003     -28.901      -6.197\n",
      "firms_creation            0.7140      0.334      2.140      0.038       0.041       1.387\n",
      "natality_rate         -1305.5091   5751.451     -0.227      0.822   -1.29e+04    1.03e+04\n",
      "unemployment_rate     -9.197e+04   7255.917    -12.675      0.000   -1.07e+05   -7.73e+04\n",
      "Valuation             -1.599e+04   7466.409     -2.141      0.038   -3.11e+04    -920.411\n",
      "Exch_rate             -2.472e+04    4.9e+04     -0.505      0.617   -1.24e+05    7.41e+04\n",
      "Fixed rate                     0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                        1.591   Durbin-Watson:                   1.573\n",
      "Prob(Omnibus):                  0.451   Jarque-Bera (JB):                0.894\n",
      "Skew:                          -0.296   Prob(JB):                        0.639\n",
      "Kurtosis:                       3.280   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "Segment 4 - Period: 2020-04-01 00:00:00 to 2023-04-01 00:00:00\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       negotiable_debts   R-squared:                       0.990\n",
      "Model:                            OLS   Adj. R-squared:                  0.987\n",
      "Method:                 Least Squares   F-statistic:                     344.6\n",
      "Date:                Sat, 30 Dec 2023   Prob (F-statistic):           3.98e-25\n",
      "Time:                        19:23:57   Log-Likelihood:                -387.10\n",
      "No. Observations:                  36   AIC:                             792.2\n",
      "Df Residuals:                      27   BIC:                             806.4\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                   1.38e+06   1.18e+05     11.707      0.000    1.14e+06    1.62e+06\n",
      "BOP                       5.9914      0.533     11.250      0.000       4.899       7.084\n",
      "business_insolvencies    -0.4107      7.209     -0.057      0.955     -15.202      14.381\n",
      "firms_creation           -0.2275      0.246     -0.927      0.362      -0.731       0.276\n",
      "natality_rate          1.717e+04   5671.606      3.027      0.005    5529.634    2.88e+04\n",
      "unemployment_rate      1.227e+04   1.26e+04      0.973      0.339   -1.36e+04    3.82e+04\n",
      "Valuation              6910.9262   8034.973      0.860      0.397   -9575.476    2.34e+04\n",
      "Exch_rate             -9.523e+04   9.59e+04     -0.993      0.329   -2.92e+05    1.01e+05\n",
      "Fixed rate             3.457e+04   5046.600      6.851      0.000    2.42e+04    4.49e+04\n",
      "==============================================================================\n",
      "Omnibus:                       10.132   Durbin-Watson:                   1.513\n",
      "Prob(Omnibus):                  0.006   Jarque-Bera (JB):                9.985\n",
      "Skew:                           0.915   Prob(JB):                      0.00679\n",
      "Kurtosis:                       4.819   Cond. No.                     7.65e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.65e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\statsmodels\\regression\\linear_model.py:1966: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extraire les dates \n",
    "breakpoint_dates = final_data.loc[breakpoints, 'DATE']\n",
    "\n",
    "# Ajustez les dates pour le premier et le dernier segment\n",
    "breakpoint_dates.iloc[0] = pd.to_datetime('2009-01-01')\n",
    "breakpoint_dates.iloc[-1] = pd.to_datetime('2023-04-01')\n",
    "\n",
    "\n",
    "# Diviser le dataframe en segments basés sur les dates de rupture\n",
    "segments = []\n",
    "for i in range(len(breakpoints) - 1):\n",
    "    start_date = pd.to_datetime(breakpoint_dates.iloc[i])\n",
    "    end_date = pd.to_datetime(breakpoint_dates.iloc[i + 1])\n",
    "    segment_data = final_data[(final_data['DATE'] >= start_date) & (final_data['DATE'] < end_date)]\n",
    "    segments.append(segment_data)\n",
    "\n",
    "\n",
    "# Ajuster une régression linéaire pour chaque segment avec statsmodels\n",
    "for i, segment_data in enumerate(segments):\n",
    "    start_date = pd.to_datetime(breakpoint_dates.iloc[i])\n",
    "    end_date = pd.to_datetime(breakpoint_dates.iloc[i + 1])\n",
    "\n",
    "    X = segment_data.drop(columns=['negotiable_debts', 'DATE', 'Deposit facility', 'Marginal lending facility'])\n",
    "    Y = segment_data['negotiable_debts']\n",
    "\n",
    "    # Ajoutez une constante à X pour estimer l'ordonnée à l'origine\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Créer un modèle de régression linéaire avec statsmodels\n",
    "    model = sm.OLS(Y, X)\n",
    "\n",
    "    # Ajuster le modèle\n",
    "    results = model.fit()\n",
    "\n",
    "    # Afficher les résultats sous forme de tableau\n",
    "    print(f\"\\nSegment {i + 1} - Period: {start_date} to {end_date}\")\n",
    "    print(results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première période (2009-avril 2012) est une période post-crise 2008. Comme attendu et commenté plus haut, le coefficient devant la colonne \"Balance of payments\", \"unemployment_rate\", \"Valuation\" sont significatifs et positif. Les coefficients devant \"firms_creation\", \"natality_rate\", \"Exch_rate\" et \"Fixed rate\" sont non significatifs sûrement dû au faible nombre de données sur cette période de 3 ans. Le coefficients devant 'business_insolvencies\" est négatif mais assez faible, tout comme dans la régression globale, ce qui s'interprète donc de la même manière. Comme changement notable, la période 2009-2012 montre une amplification de l'effet de la balance des paiements sur la dette, et une relative stabilité des insolvabilités par rapport à la période complète\n",
    "\n",
    "La seconde période, entre 2012 et 2016, est marquée par une stagnation économique, un chômage grimpant et une crise dans les échanges européens. \n",
    "Comparé au segment précédent, plusieurs changements dans les coefficients sont notables :\n",
    "Le coefficient devant \"BOP\" diminue à 4.61, montrant une moindre dépendance aux échanges internationaux. Cela peut refléter une période de stabilisation après une croissance rapide des échanges dans le segment précédent.\n",
    "Peu de coefficients sont en fait toujours significatif au seuil de 10%\n",
    "\n",
    "La troisième période, entre 2016 et 2020, est toujours une période dde stagnation économique. Le coeffiicient devant le taux de chômage devient significatif au niveau 1% et est trés bas. Le coefficient devant \"Valuation\" est significatif, comme à la première période, mais cette fois de signe opposé, il est désormais négatif. Un coefficient négatif devant \"Valuation\" suggère qu'une dépréciation de l'euro par rapport au dollar est associée à une diminution de la dette publique en France. Cela peut résulter de l'impact positif sur les exportations, réduisant la nécessité d'emprunter. De plus, si une part significative de la dette est libellée en devises étrangères, une dépréciation augmente sa valeur en euros. Cependant, l'interprétation dépend de divers facteurs économiques.\n",
    "\n",
    "La dernière période, après avril 2020 est la période durant laquelle le COVID a fragilisé l'économie française. Les seuls régresseurs ayant des coefficients significatifs sont \"BOP\" et \"Fixed rate\". Ceci ne semble pas absurde dans une situation où les échanges commerciaux ont connu de fortes fluctuations (à la baisse puis à la hausse), et à un moment où la BCE a relevé ses taux afin de limiter l'inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essai et comparaison de nouveaux modèles prédictifs\n",
    "\n",
    "La dernière partie de ce projet sur la dette négociable de l'Etat français vise à étudier d'autres formes de régressions, la régression linéaire n'étant pas unique. Après plusieurs recherches sur leur existence et sur leur implantation informatique, nous avons trouvé les Arbres de décisions, les Forêts aléatoires et les modèles Adaboost. \n",
    "On commencer par évaluer  quatre modèles (Régression Linéaire, Arbre de Décision, Forêt Aléatoire et AdaBoost) en utilisant la validation croisée pour calculer les scores RMSE (Root Mean Squared Error) pour chaque pli et affiche la moyenne RMSE pour chaque modèle.\n",
    "\n",
    "Le principe ici est le suivant : La validation croisée divise l'ensemble de données en plusieurs plis et évalue le modèle sur chacun d'entre eux.\n",
    "On entraine alors le modèle plusieurs fois selon le nombre de division, chaque fois en utilisant un pli différent comme ensemble de test et les autres comme ensembles d'entraînements. Puis pour chaque pli on évalue la performance en calculant le RMSE, et on fait enfin la moyenne des RMSE. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle: Régression Linéaire\n",
      "RMSE scores: 0    59336.03\n",
      "1    66908.69\n",
      "2    68466.28\n",
      "3    63349.78\n",
      "4    52888.35\n",
      "Name: RMSE, dtype: float64\n",
      "Moyenne RMSE: 62189.826\n",
      "\n",
      "Modèle: Arbre de Décision\n",
      "RMSE scores: 0     38912.06\n",
      "1    208162.06\n",
      "2     67657.75\n",
      "3    110944.48\n",
      "4     30032.66\n",
      "Name: RMSE, dtype: float64\n",
      "Moyenne RMSE: 91141.802\n",
      "\n",
      "Modèle: Forêt Aléatoire\n",
      "RMSE scores: 0     26214.79\n",
      "1    137295.39\n",
      "2     70752.30\n",
      "3     33768.78\n",
      "4     74839.24\n",
      "Name: RMSE, dtype: float64\n",
      "Moyenne RMSE: 68574.1\n",
      "\n",
      "Modèle: AdaBoost\n",
      "RMSE scores: 0    31236.39\n",
      "1    32071.19\n",
      "2    66280.39\n",
      "3    33844.17\n",
      "4    30997.05\n",
      "Name: RMSE, dtype: float64\n",
      "Moyenne RMSE: 38885.838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = final_data[selected_columns]\n",
    "X = df.drop('negotiable_debts', axis=1)\n",
    "y = df['negotiable_debts']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Les Modèles qu'on a choisit\n",
    "models = {\n",
    "    'Régression Linéaire': LinearRegression(),\n",
    "    'Arbre de Décision': DecisionTreeRegressor(),\n",
    "    'Forêt Aléatoire': RandomForestRegressor(),\n",
    "    'AdaBoost': AdaBoostRegressor()\n",
    "}\n",
    "\n",
    "# Évaluation des modèles avec la validation croisée\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = pd.Series(-scores, name=\"RMSE\").apply(lambda x: round(x ** 0.5, 2))\n",
    "    print(f\"Modèle: {model_name}\")\n",
    "    print(\"RMSE scores:\", rmse_scores)\n",
    "    print(f\"Moyenne RMSE: {rmse_scores.mean()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation des Résultats :\n",
    "\n",
    "### Régression Linéaire :\n",
    "Les RMSE varient significativement d'un pli à l'autre.\n",
    "La moyenne RMSE est relativement élevée (62189.83), indiquant une dispersion importante des erreurs de prédiction.\n",
    "\n",
    "###Arbre de Décision :\n",
    "Les RMSE sont très variables, avec un écart élevé entre le meilleur et le pire pli.\n",
    "La moyenne RMSE est élevée (80897.62), suggérant une performance mitigée du modèle.\n",
    "\n",
    "### Forêt Aléatoire :\n",
    "Les RMSE montrent une variabilité, mais moins prononcée que pour l'Arbre de Décision.\n",
    "La moyenne RMSE (68686.13) est relativement élevée, indiquant que le modèle ne parvient pas à prédire de manière précise.\n",
    "\n",
    "### AdaBoost :\n",
    "Les RMSE sont plus homogènes entre les plis par rapport à d'autres modèles.\n",
    "La moyenne RMSE (35294.03) est relativement basse, suggérant une meilleure performance en termes de précision de prédiction.\n",
    "\n",
    "Le modèle avec la moyenne RMSE la plus faible est donc le modèle Adaboost. \n",
    "\n",
    "## Deuxième phase : prédiction et comparaison des modèles\n",
    "L'approche ici est différente. L'objectif ici est d'appliquer les 4 modèles de régression afin de prédire la variable cible (la dette) à un instant T, par les données des régresseurs aux instants [2009-01-01 - T]. Puis, dans un second temps, comparer les prédictions des modèles entre eux, à chaque date, et les comparer à la vraie valeur de la dette à cette date donnée. \n",
    "Ensuite, le code utilise une boucle pour itérer sur les dates, entraîne les modèles sur l'ensemble d'entraînement à chaque itération, fait des prédictions sur l'ensemble de test, et stocke ces prédictions dans le DataFrame final_data. Enfin, il affiche la somme des MSE (Mean Squared Error) pour chaque modèle.\n",
    "\n",
    "Le principe est alors le suivant : La boucle itère sur chaque date à partir de la deuxième date dans le jeu de données.À chaque itération, les données jusqu'à la date actuelle sont utilisées pour l'entraînement, tandis que les données à la date actuelle sont utilisées pour les tests.\n",
    "On entraine ensuite le modèle : Pour chaque date, les modèles sélectionnés (Régression Linéaire, Arbre de Décision, Forêt Aléatoire, AdaBoost) sont entraînés sur les caractéristiques sélectionnées jusqu'à la date actuelle.Puis on fait des prédictions à la datte actuelle, la prédiction est stockée et ajoutée à la base de données pour chaque modèles. Enfin on calcule la MSE (mean squared error) pour chaque modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:47<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somme des MSE pour Régression Linéaire: 520653518.0153163\n",
      "Somme des MSE pour Arbre de Décision: 85053923228.0\n",
      "Somme des MSE pour Forêt Aléatoire: 218396888722.18256\n",
      "Somme des MSE pour AdaBoost: 228080195475.8575\n",
      "5 dernières lignes de final_data :\n",
      "          DATE  negotiable_debts       BOP  business_insolvencies  \\\n",
      "167 2022-12-01         2277811.0  104521.0            4003.000000   \n",
      "168 2023-01-01         2297631.0  109080.0            4872.000000   \n",
      "169 2023-02-01         2319193.0  109849.0            4872.000000   \n",
      "170 2023-03-01         2328956.0  109785.0            4872.000000   \n",
      "171 2023-04-01         2352050.0  109339.0            4488.666667   \n",
      "\n",
      "     firms_creation  natality_rate  unemployment_rate  Valuation  Exch_rate  \\\n",
      "167         89608.0           10.0           6.933333    6.47376     1.0702   \n",
      "168         89832.0            9.6           6.900000    7.08242     1.0862   \n",
      "169         85940.0            9.8           6.933333    7.26793     1.0576   \n",
      "170         99475.0            9.4           6.966667    7.32239     1.0839   \n",
      "171         85602.0            9.3           7.000000    7.49150     1.1020   \n",
      "\n",
      "     Deposit facility  Fixed rate  Marginal lending facility  \\\n",
      "167               2.0         2.5                       2.75   \n",
      "168               2.0         2.5                       2.75   \n",
      "169               2.5         3.0                       3.25   \n",
      "170               3.0         3.5                       3.75   \n",
      "171               3.0         3.5                       3.75   \n",
      "\n",
      "     Régression Linéaire_Prediction  Arbre de Décision_Prediction  \\\n",
      "167                       2277811.0                     2266628.0   \n",
      "168                       2297631.0                     2277811.0   \n",
      "169                       2319193.0                     2277811.0   \n",
      "170                       2328956.0                     2266628.0   \n",
      "171                       2352050.0                     2328956.0   \n",
      "\n",
      "     Forêt Aléatoire_Prediction  AdaBoost_Prediction  \n",
      "167                  2245571.72         2.224432e+06  \n",
      "168                  2250854.67         2.218064e+06  \n",
      "169                  2274327.22         2.268152e+06  \n",
      "170                  2299458.97         2.274087e+06  \n",
      "171                  2302101.94         2.277459e+06  \n",
      "\n",
      "5 premières lignes de final_data :\n",
      "        DATE  negotiable_debts      BOP  business_insolvencies  \\\n",
      "0 2009-01-01         1018094.0  55163.0                 5758.0   \n",
      "1 2009-02-01         1040865.0  54216.0                 5758.0   \n",
      "2 2009-03-01         1063788.0  52910.0                 5758.0   \n",
      "3 2009-04-01         1074757.0  52416.0                 5316.0   \n",
      "4 2009-05-01         1092161.0  54464.0                 5316.0   \n",
      "\n",
      "   firms_creation  natality_rate  unemployment_rate  Valuation  Exch_rate  \\\n",
      "0         39666.0           12.5           8.200000    2.97392     1.2782   \n",
      "1         45656.0           12.3           8.433333    2.70248     1.2669   \n",
      "2         57577.0           12.2           8.666667    2.80734     1.3251   \n",
      "3         56132.0           12.4           8.900000    3.15985     1.3226   \n",
      "4         48641.0           12.4           8.900000    3.27765     1.4154   \n",
      "\n",
      "   Deposit facility  Fixed rate  Marginal lending facility  \\\n",
      "0              1.00        2.00                       3.00   \n",
      "1              1.00        2.00                       3.00   \n",
      "2              0.50        1.50                       2.50   \n",
      "3              0.25        1.25                       2.25   \n",
      "4              0.25        1.00                       1.75   \n",
      "\n",
      "   Régression Linéaire_Prediction  Arbre de Décision_Prediction  \\\n",
      "0                             NaN                           NaN   \n",
      "1                    1.018094e+06                     1018094.0   \n",
      "2                    1.065249e+06                     1040865.0   \n",
      "3                    1.074765e+06                     1063788.0   \n",
      "4                    1.092125e+06                     1063788.0   \n",
      "\n",
      "   Forêt Aléatoire_Prediction  AdaBoost_Prediction  \n",
      "0                         NaN                  NaN  \n",
      "1                  1018094.00            1018094.0  \n",
      "2                  1034716.83            1040865.0  \n",
      "3                  1049372.35            1063788.0  \n",
      "4                  1061376.59            1040865.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Créer un dictionnaire pour stocker les métriques pour chaque modèle\n",
    "metrics_scores = {model_name: {'MSE': []} for model_name in models.keys()}\n",
    "\n",
    "# Créer un nouveau DataFrame pour stocker les prédictions\n",
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "# Variables explicatives\n",
    "features = ['BOP', 'business_insolvencies', 'firms_creation', 'natality_rate', 'unemployment_rate', 'Valuation', 'Exch_rate', 'Fixed rate', 'negotiable_debts']\n",
    "\n",
    "# Créer un dictionnaire pour stocker les MSE pour chaque modèle\n",
    "mse_scores = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "# Désactiver les avertissements pendant l'exécution de la boucle\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Boucle sur les dates à partir de la deuxième date\n",
    "    for i in tqdm(range(1, len(final_data))):\n",
    "        # Séparer les données en ensemble d'entraînement et de test\n",
    "        train_data = final_data.iloc[:i, :]\n",
    "        test_data = final_data.iloc[i, :]\n",
    "\n",
    "        # Sélectionner les caractéristiques et la cible\n",
    "        X_train = train_data[features]\n",
    "        y_train = train_data['negotiable_debts']\n",
    "        X_test = test_data[features]\n",
    "\n",
    "        # Boucle sur les modèles\n",
    "        for model_name, model in models.items():\n",
    "            # Entraîner le modèle\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Faire la prédiction sur les données de test\n",
    "            y_pred = model.predict(X_test.values.reshape(1, -1))\n",
    "\n",
    "            # Ajouter les prédictions au DataFrame final_data\n",
    "            final_data.at[test_data.name, f'{model_name}_Prediction'] = y_pred[0]\n",
    "\n",
    "            # Calculer les métriques et les ajouter aux listes correspondantes\n",
    "            mse = mean_squared_error([test_data['negotiable_debts']], [y_pred])\n",
    "\n",
    "            metrics_scores[model_name]['MSE'].append(mse)\n",
    "\n",
    "# Afficher les métriques pour chaque modèle\n",
    "for model_name, metrics_dict in metrics_scores.items():\n",
    "    total_mse = np.sum(metrics_dict['MSE'])\n",
    "    print(f'Somme des MSE pour {model_name}: {total_mse}')\n",
    "   \n",
    "# Afficher les 5 dernières lignes\n",
    "print(\"5 dernières lignes de final_data :\")\n",
    "print(final_data.tail())\n",
    "\n",
    "# Afficher les 5 premières lignes\n",
    "print(\"\\n5 premières lignes de final_data :\")\n",
    "print(final_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somme des MSE pour Chaque Modèle :\n",
    "\n",
    "La somme des MSE est la plus basse pour la Régression Linéaire, indiquant une performance globale relativement meilleure par rapport aux autres modèles.\n",
    "L'Arbre de Décision a une somme des MSE très élevée, soulignant une faible capacité du modèle à généraliser.\n",
    "Forêt Aléatoire et AdaBoost ont des sommes intermédiaires, avec AdaBoost présentant une performance légèrement meilleure.\n",
    "\n",
    "### Pourquoi les résultats diffèrent selon l'approche par les RMSE et les MSE ? \n",
    "Le RMSE moyen privilégie les modèles qui minimisent les erreurs pour chaque pli, même si cela conduit à quelques erreurs importantes.\n",
    "La somme des MSE évalue les modèles en fonction de la contribution totale des erreurs, ce qui peut montrer que la Régression Linéaire a une performance plus stable sur l'ensemble des donnée. Cela peut signifier que la Régression Linéaire a moins tendance à générer des erreurs très importantes. \n",
    "\n",
    "### Conclusion \n",
    "En conclusion, même si le RMSE moyen pour AdaBoost semble meilleur, la somme des MSE indique que la Régression Linéaire peut présenter une performance plus stable et globalement meilleure sur l'ensemble des données. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm
import os 
import numpy as np

data_folder = 'datas/'

# Charger le DataFrame à partir du fichier CSV
final_data = pd.read_csv(os.path.join(data_folder, 'final_data.csv'), parse_dates=['DATE'])

# Ajouter les colonnes à retirer à la liste selected_columns
selected_columns = ['BOP', 'business_insolvencies', 'firms_creation', 'natality_rate', 'unemployment_rate', 'Valuation', 'Exch_rate', 'Fixed rate', 'negotiable_debts']
# Garder uniquement les colonnes spécifiées dans selected_columns
df = final_data[selected_columns]

# Séparation des données en features (X) et target (y)
X = df.drop(columns=['negotiable_debts'])
y = df['negotiable_debts']



# Séparation des données en ensemble d'entraînement et ensemble de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modèles à évaluer
models = {
    'Régression Linéaire': LinearRegression(),
    'Arbre de Décision': DecisionTreeRegressor(),
    'Forêt Aléatoire': RandomForestRegressor(),
    'AdaBoost': AdaBoostRegressor()
}

# Évaluation des modèles avec la validation croisée
for model_name, model in models.items():
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
    rmse_scores = pd.Series(-scores, name="RMSE").apply(lambda x: round(x ** 0.5, 2))
    print(f"Modèle: {model_name}")
    print("RMSE scores:", rmse_scores)
    print(f"Moyenne RMSE: {rmse_scores.mean()}\n")



# Créer un dictionnaire pour stocker les métriques pour chaque modèle
metrics_scores = {model_name: {'MSE': [], 'R2': [], 'MAE': []} for model_name in models.keys()}
# Créer un nouveau DataFrame pour stocker les prédictions
predictions_df = pd.DataFrame()

# Variables explicatives
features = ['BOP', 'business_insolvencies', 'firms_creation', 'natality_rate', 'unemployment_rate', 'Valuation', 'Exch_rate', 'Fixed rate', 'negotiable_debts']

# Créer un dictionnaire pour stocker les MSE pour chaque modèle
mse_scores = {model_name: [] for model_name in models.keys()}

# Boucle sur les dates à partir de la deuxième date
for i in tqdm(range(1, len(final_data))):
    # Séparer les données en ensemble d'entraînement et de test
    train_data = final_data.iloc[:i, :]
    test_data = final_data.iloc[i, :]

    # Sélectionner les caractéristiques et la cible
    X_train = train_data[features]
    y_train = train_data['negotiable_debts']
    X_test = test_data[features]

    # Boucle sur les modèles
    for model_name, model in models.items():
        # Entraîner le modèle
        model.fit(X_train, y_train)

        # Faire la prédiction sur les données de test
        y_pred = model.predict(X_test.values.reshape(1, -1))

        # Ajouter les prédictions au DataFrame final_data
        final_data.at[test_data.name, f'{model_name}_Prediction'] = y_pred[0]

        # Calculer les métriques et les ajouter aux listes correspondantes
        mse = mean_squared_error([test_data['negotiable_debts']], [y_pred])

        metrics_scores[model_name]['MSE'].append(mse)


# Afficher les métriques pour chaque modèle
for model_name, metrics_dict in metrics_scores.items():
    total_mse = np.sum(metrics_dict['MSE'])
    print(f'Somme des MSE pour {model_name}: {total_mse}')
   
# Enregistrer le DataFrame final_data dans un fichier CSV dans le dossier 'data_modelisation'
output_folder = 'data_modelisation'
output_filename = 'datas_with_predictions.csv'
output_path = os.path.join(output_folder, output_filename)

final_data.to_csv(output_path, index_label='Date')

print(f"Le fichier {output_filename} a été enregistré dans le dossier {output_folder}.")

